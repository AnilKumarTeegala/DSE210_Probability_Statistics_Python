{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 5 Generative models I \n",
    "## author: Michael Galarnyk\n",
    "\n",
    "#### Get the Training data and find πj (Calculate fraction of documents in each class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "full_path = '/Users/mgalarny/Documents/youtube/DSE210_Probability_Statistics_Python/20news-bydate/matlab/'\n",
    "\n",
    "#Get the training data\n",
    "training_data = pd.read_csv(full_path + 'train.label', delim_whitespace=True, names=['label_idx'])\n",
    "training_data['doc_idx'] = training_data.index\n",
    "pi_j = training_data.groupby(['label_idx']).agg({'doc_idx':'count'})/len(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a multinomial Naive Bayes model using the training data πj\n",
    "\n",
    "## Get the fraction of documents that belong to each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_idx</th>\n",
       "      <th>Pi_j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.042595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.051557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.050759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.052090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.051025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_idx      Pi_j\n",
       "0          1  0.042595\n",
       "1          2  0.051557\n",
       "2          3  0.050759\n",
       "3          4  0.052090\n",
       "4          5  0.051025"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_prob = Y.groupby(['label_idx']).agg({'doc_idx': 'count'})/len(Y)\n",
    "class_prob = class_prob.rename(columns = {'doc_idx': 'Pi_j'})\n",
    "class_prob = class_prob.reset_index()\n",
    "class_prob.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P<sub>j</sub>\n",
    "### Find the probability distribution over V that models the documents for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000016915"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_jw = pd.merge(X,Y,how='inner',on='doc_idx')\n",
    "P_jw = P_jw.groupby(['word_idx', 'label_idx']).agg({'occurance_count':sum}).reset_index()\n",
    "\n",
    "P_jw = pd.merge(right=P_jw, left=s, how='outer', on=['word_idx','label_idx']).fillna(value=0)\n",
    "P_jw['x_smooth'] = P_jw['occurance_count']+1\n",
    "P_jw = P_jw.groupby(['label_idx', 'word_idx']).agg({'x_smooth':sum})\n",
    "P_jw = P_jw.groupby(level=0).transform(lambda x: x/x.sum())\n",
    "P_jw.columns = ['P_j']\n",
    "#P_jw['P_j'] = P_jw['x_smooth'] / sum(P_jw['x_smooth'] )\n",
    "P_jw = P_jw.reset_index()\n",
    "P_jw[P_jw['label_idx'] == 20].P_j.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying new documents\n",
    "This function takes a dataframe with doc_idx, word_idx, and count and classifies it to return a dataframe with the document_id and label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_idx</th>\n",
       "      <th>label_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_idx  label_idx\n",
       "0        4         16"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classify(data):\n",
    "    a = pd.merge(data, P_jw, on='word_idx')\n",
    "    b = pd.merge(a, class_prob, on='label_idx' )\n",
    "    b['xlogp'] = b['occurance_count']*b['P_j'].apply(lambda x: log(x))\n",
    "    b = b.groupby(['doc_idx', 'label_idx', 'Pi_j']).agg({'xlogp':sum})\n",
    "    b = b.reset_index()\n",
    "    b['logPi_j'] = b['Pi_j'].apply(lambda x: log(x))\n",
    "    b['calc'] = b['logPi_j'] + b['xlogp']\n",
    "    b[['doc_idx','label_idx', 'calc']]\n",
    "    idx = b.groupby(['doc_idx'])['calc'].transform(max) == b['calc']\n",
    "    predict = b[idx][['doc_idx','label_idx']].reset_index()\n",
    "    return predict[['doc_idx', 'label_idx']]\n",
    "\n",
    "#this is to test the classifier\n",
    "test_classifier_data = X_test[X_test['doc_idx']==4]\n",
    "classify(test_classifier_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Accuracy\n",
    "This checks the accuracy of the model againsts all of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.76767676767676"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_accuracy(data, label):\n",
    "    predict = classify(data)\n",
    "    check = pd.merge(label, predict, on=['doc_idx'])\n",
    "    check['compare'] = check['label_idx_x'] - check['label_idx_y']\n",
    "    accuracy = len(check[check['compare'] == 0])*100/len(check)\n",
    "    return accuracy\n",
    "    \n",
    "#this is to test the classifier\n",
    "test_classifier_data = X_test[X_test['doc_idx']<100]\n",
    "test_classifier_label = Y_test[Y_test['doc_idx']<100]\n",
    "check_accuracy(test_classifier_data, test_classifier_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 78.107928048\n",
      "Error Rate:  21.892071952\n"
     ]
    }
   ],
   "source": [
    "c = check_accuracy(X_test, Y_test)\n",
    "print \"Precision:\", c\n",
    "#Error Rate:\n",
    "print \"Error Rate: \", 100-c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better-performing Model\n",
    "Get a better performing mode.  Currently, I'm at an accuracy of 78%.  If I want to get a better match...\n",
    "\n",
    "#### Split the training model into a smaller training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 15.548455804046853],\n",
       " [5, 15.002219263204623],\n",
       " [6, 13.84451544195953],\n",
       " [7, 14.045991298943449],\n",
       " [8, 13.849431818181813],\n",
       " [9, 11.341853035143771],\n",
       " [10, 13.94316163410302],\n",
       " [11, 14.0625],\n",
       " [12, 12.034078807241741],\n",
       " [13, 14.31870669745959],\n",
       " [14, 13.805970149253724],\n",
       " [15, 13.98135818908122],\n",
       " [16, 14.630681818181813],\n",
       " [17, 13.74622356495469],\n",
       " [18, 11.821086261980824],\n",
       " [19, 13.827993254637434],\n",
       " [20, 12.433392539964473],\n",
       " [21, 14.179104477611943],\n",
       " [22, 13.671875],\n",
       " [23, 13.70143149284253],\n",
       " [24, 12.153518123667382]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the vocab\n",
    "def vocab(words,label_count,reduce_vocab=False):\n",
    "    ##tweek vocabulary here\n",
    "    if reduce_vocab == True:\n",
    "        words = words[:40000]\n",
    "\n",
    "    s = pd.Series([i+1 for i in range(label_count)], index=[i+1 for i in range(20)]).to_frame()\n",
    "    s['key'] = 1\n",
    "    s.columns = ['label_idx', 'key']\n",
    "    s = pd.merge(words, s, on='key')\n",
    "    return s\n",
    "\n",
    "#next get Pi_j\n",
    "def Pi_j(label):\n",
    "    class_prob = label.groupby(['label_idx']).agg({'doc_idx': 'count'})/len(Y)\n",
    "    class_prob = class_prob.rename(columns = {'doc_idx': 'Pi_j'})\n",
    "    class_prob = class_prob.reset_index()\n",
    "    return class_prob\n",
    "\n",
    "#now get P_jw\n",
    "def P_jw(data, label, vocab):\n",
    "    #use inputs here\n",
    "    P_jw = pd.merge(data,label,how='inner',on='doc_idx')\n",
    "    s = vocab\n",
    "    \n",
    "    #calcs here\n",
    "    P_jw = P_jw.groupby(['word_idx', 'label_idx']).agg({'occurance_count':sum}).reset_index()\n",
    "    P_jw = pd.merge(right=P_jw, left=s, how='outer', on=['word_idx','label_idx']).fillna(value=0)\n",
    "    P_jw['x_smooth'] = P_jw['occurance_count']+1\n",
    "    P_jw = P_jw.groupby(['label_idx', 'word_idx']).agg({'x_smooth':sum})\n",
    "    P_jw = P_jw.groupby(level=0).transform(lambda x: x/x.sum())\n",
    "    P_jw.columns = ['P_j']\n",
    "    P_jw = P_jw.reset_index()\n",
    "    \n",
    "    return P_jw\n",
    "\n",
    "def classify(data, P_jw, Pi_j):    \n",
    "    #use inputs here\n",
    "    a = pd.merge(data, P_jw, on='word_idx')\n",
    "    b = pd.merge(a, Pi_j, on='label_idx' )\n",
    "    \n",
    "    \n",
    "    b['xlogp'] = b['occurance_count']*b['P_j'].apply(lambda x: log(x))\n",
    "    b = b.groupby(['doc_idx', 'label_idx', 'Pi_j']).agg({'xlogp':sum})\n",
    "    b = b.reset_index()\n",
    "    b['logPi_j'] = b['Pi_j'].apply(lambda x: log(x))\n",
    "    b['calc'] = b['logPi_j'] + b['xlogp']\n",
    "    b[['doc_idx','label_idx', 'calc']]\n",
    "    idx = b.groupby(['doc_idx'])['calc'].transform(max) == b['calc']\n",
    "    predict = b[idx][['doc_idx','label_idx']].reset_index()\n",
    "    \n",
    "    return predict[['doc_idx', 'label_idx']]\n",
    "\n",
    "def check_accuracy(data, label, P_jw, Pi_j):\n",
    "    predict = classify(data, P_jw, Pi_j)\n",
    "    check = pd.merge(label, predict, on=['doc_idx'])\n",
    "    check['compare'] = check['label_idx_x'] - check['label_idx_y']\n",
    "    accuracy = len(check[check['compare'] == 0])*100/len(check)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "#I'm going to split the data with a modulo of the doc_idx.\n",
    "# Modulo 4 gets every fourth doc_idx...which is roughly 25% of all documents\n",
    "# Modulo 5 gets every fifth doc_idx... which is roughly 20% of all documents\n",
    "# Modulo 6 gets every sixth doc_idx.. and so on\n",
    "results = []\n",
    "validation = []\n",
    "for i in range(4,25):\n",
    "    X_validate = X[X['doc_idx']%i == 0]\n",
    "    X_split = X[X['doc_idx']%i != 0]\n",
    "\n",
    "    Y_validate = Y[Y['doc_idx']%i == 0]\n",
    "    Y_split = Y[Y['doc_idx']%i != 0]\n",
    "\n",
    "    df_Pi_j = Pi_j(Y_split)\n",
    "    df_P_jw = P_jw(X_split, Y_split, vocab(V,20))\n",
    "    #classify(X_validate, df_P_jw, df_Pi_j)\n",
    "\n",
    "    validation.append([i, 100-check_accuracy(X_validate, Y_validate, df_P_jw, df_Pi_j)]) \n",
    "    #results.append([i, check_accuracy(X, Y, df_P_jw, df_Pi_j)])\n",
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results\n",
    "#after running this, it seems that modulo 9 gets the highest accuracy for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 84.95339547270306, True],\n",
       " [5, 15.002219263204623, False],\n",
       " [6, 86.10223642172524, True],\n",
       " [6, 13.84451544195953, False],\n",
       " [7, 85.95400870105655, True],\n",
       " [7, 14.045991298943449, False],\n",
       " [8, 86.15056818181819, True],\n",
       " [8, 13.849431818181813, False],\n",
       " [9, 88.65814696485623, True],\n",
       " [9, 11.341853035143771, False],\n",
       " [10, 86.05683836589698, True],\n",
       " [10, 13.94316163410302, False],\n",
       " [11, 85.83984375, True],\n",
       " [11, 14.0625, False],\n",
       " [12, 87.96592119275826, True],\n",
       " [12, 12.034078807241741, False],\n",
       " [13, 85.56581986143188, True],\n",
       " [13, 14.31870669745959, False],\n",
       " [14, 86.19402985074628, True],\n",
       " [14, 13.805970149253724, False],\n",
       " [15, 86.01864181091878, True],\n",
       " [15, 13.98135818908122, False],\n",
       " [16, 85.36931818181819, True],\n",
       " [16, 14.630681818181813, False],\n",
       " [17, 86.404833836858, True],\n",
       " [17, 13.74622356495469, False],\n",
       " [18, 88.17891373801918, True],\n",
       " [18, 11.821086261980824, False],\n",
       " [19, 86.17200674536257, True],\n",
       " [19, 13.827993254637434, False]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "#define the vocab\n",
    "def vocab(words,label_count,reduce_vocab=False):\n",
    "    ##tweek vocabulary here\n",
    "    if reduce_vocab == True:\n",
    "        words = [(word_idx,word, key) for (a, word,word_idx,key) in words.itertuples() if word not in stop_words]\n",
    "        words = pd.DataFrame(data=words, columns=['word_idx', 'word','key'])\n",
    "\n",
    "    s = pd.Series([i+1 for i in range(label_count)], index=[i+1 for i in range(20)]).to_frame()\n",
    "    s['key'] = 1\n",
    "    s.columns = ['label_idx', 'key']\n",
    "    s = pd.merge(words, s, on='key')\n",
    "    return s\n",
    "\n",
    "len(vocab(V,20,reduce_vocab=True)), len(vocab(V,20,reduce_vocab=False))\n",
    "\n",
    "validation = []\n",
    "for i in range(5,20):\n",
    "    X_validate = X[X['doc_idx']%i == 0]\n",
    "    X_split = X[X['doc_idx']%i != 0]\n",
    "\n",
    "    Y_validate = Y[Y['doc_idx']%i == 0]\n",
    "    Y_split = Y[Y['doc_idx']%i != 0]\n",
    "\n",
    "    df_Pi_j = Pi_j(Y_split)\n",
    "    df_P_jw = P_jw(X_split, Y_split, vocab(V,20,True))\n",
    "    validation.append([i, check_accuracy(X_validate, Y_validate, df_P_jw, df_Pi_j), True]) \n",
    "    \n",
    "    df_P_jw = P_jw(X_split, Y_split, vocab(V,20,False))\n",
    "    validation.append([i, 100-check_accuracy(X_validate, Y_validate, df_P_jw, df_Pi_j), False]) \n",
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's try replacing the frequency (f) of a word by log(1+f)\n",
    "We will not use the modified Vocabulary (without stop_words), because it didn't really improve the overall precision of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 11.66134185303514, False]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def P_jw(data, label, vocab):\n",
    "    #use inputs here\n",
    "    P_jw = pd.merge(data,label,how='inner',on='doc_idx')\n",
    "    s = vocab\n",
    "    \n",
    "    #calcs here\n",
    "    P_jw = P_jw.groupby(['word_idx', 'label_idx']).agg({'occurance_count':sum}).reset_index()\n",
    "    P_jw = pd.merge(right=P_jw, left=s, how='outer', on=['word_idx','label_idx']).fillna(value=0)\n",
    "    \n",
    "    #this is where we replace the frequency of a word by log(1+f)\n",
    "    P_jw['x_smooth'] = P_jw['occurance_count'].apply(lambda x: log(x+2))\n",
    "    P_jw = P_jw.groupby(['label_idx', 'word_idx']).agg({'x_smooth':sum})\n",
    "    P_jw = P_jw.groupby(level=0).transform(lambda x: x/x.sum())\n",
    "    P_jw.columns = ['P_j']\n",
    "    P_jw = P_jw.reset_index()\n",
    "    \n",
    "    return P_jw\n",
    "\n",
    "results = []\n",
    "for i in range(9,10):\n",
    "    X_validate = X[X['doc_idx']%i == 0]\n",
    "    X_split = X[X['doc_idx']%i != 0]\n",
    "\n",
    "    Y_validate = Y[Y['doc_idx']%i == 0]\n",
    "    Y_split = Y[Y['doc_idx']%i != 0]\n",
    "\n",
    "    df_P_jw = P_jw(X_split, Y_split, vocab(V,20))\n",
    "    results.append([i, 100-check_accuracy(X_validate, Y_validate, df_P_jw, df_Pi_j), False])\n",
    "results\n",
    "#The results are not as good..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuracy out of the options I've tried comes from splitting the training data by modulo 9...and it doesn't matter whether we pull our the stop_words from the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
