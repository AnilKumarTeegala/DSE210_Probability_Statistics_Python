{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 5 Generative models I \n",
    "# author: Michael Galarnyk test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def read_data(path, file_name):\n",
    "    with open(os.path.join(path, file_name), 'r') as f:\n",
    "        data_dic = {}\n",
    "        increment = 0\n",
    "        for line in f:\n",
    "            doc_word_count_gen = (int(i) for i in line.split()) # generator comprehension\n",
    "            doc_id = next(doc_word_count_gen)\n",
    "            word_id = next(doc_word_count_gen)\n",
    "            count = next(doc_word_count_gen)\n",
    "            data_dic[increment] =  [doc_id, word_id, count] \n",
    "            increment +=1\n",
    "        data_dic = np.array(data_dic.values())\n",
    "    return data_dic\n",
    "\n",
    "#path = '20news-bydate/matlab/'\n",
    "#data_array = read_data(path, 'train.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_label(path, file_name):\n",
    "    with open(os.path.join(path, file_name), 'r') as f:\n",
    "        label_list = [0]\n",
    "        classify = [0 for i in range(21)]\n",
    "        for line in f:\n",
    "            label_list.append(int(line))\n",
    "            classify[int(line)] += 1\n",
    "        classify = map(lambda x: 1.0 * x / len(label_list), classify)\n",
    "        label_array = np.array(label_list)\n",
    "        pi = np.array(classify)\n",
    "        pi[0] = 1.0\n",
    "        pi = np.log2(pi)\n",
    "    return label_array, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_multinomial_model(label, data):\n",
    "    m = np.zeros((21, 61189))\n",
    "    len_data = data.shape[0]\n",
    "    for i in range(len_data):\n",
    "        data_iter = iter(data[i])\n",
    "        doc_id = next(data_iter)\n",
    "        word_id = next(data_iter)\n",
    "        count = next(data_iter)\n",
    "        classify = label[doc_id]\n",
    "        m[classify][word_id] += count\n",
    "    # Remove stop words\n",
    "    stop_word = {12:\"of\", 23:\"and\",139:\"an\",978:\"am\",297:\"at\",51:\"but\",52:\"with\",33:\"to\",48:\"on\",27:\"are\",29:\"the\",72:\"can\",1367:\"else\",81:\"for\",301:\"he\",389:\"she\",99:\"so\"}\n",
    "    for k in stop_word:\n",
    "        m[:, k] = 0.0\n",
    "    m += 1\n",
    "    m[:,0] = 0.0\n",
    "    s = np.sum(m, axis = 1)\n",
    "    s_trans = np.transpose([s])\n",
    "    m = m / s_trans\n",
    "    m[:,0] = 1.0\n",
    "    m = np.log2(m)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naive_bayes(m, pi, test_data, test_label):\n",
    "    len_test_data = test_data.shape[0]\n",
    "    number_doc_plus_1 = len(test_label)\n",
    "    test_m = np.zeros((number_doc_plus_1, 61189))\n",
    "    for i in range(len_test_data):\n",
    "        data_iter = iter(test_data[i])\n",
    "        doc_id = next(data_iter)\n",
    "        word_id = next(data_iter)\n",
    "        count = next(data_iter)\n",
    "        test_m[doc_id][word_id] += count\n",
    "\n",
    "    # log(1+f)\n",
    "    test_m = np.log2(1+test_m)\n",
    "    error = 0\n",
    "    for i in xrange(1, number_doc_plus_1):\n",
    "        cur_doc = test_m[i]\n",
    "        cur_s = np.sum(cur_doc * m, axis = 1)\n",
    "        final = cur_s + pi\n",
    "        final = final[1:]\n",
    "        label = np.argmax(final) + 1\n",
    "        if label != test_label[i]:\n",
    "            error += 1\n",
    "    return error * 100.0 / (number_doc_plus_1 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate:  20.546302465\n"
     ]
    }
   ],
   "source": [
    "path = '20news-bydate/matlab/'\n",
    "label_array, pi = read_label(path, 'train.label')\n",
    "data_array = read_data(path, 'train.data')\n",
    "m = setup_multinomial_model(label_array, data_array)\n",
    "\n",
    "test_label, _ = read_label(path, 'test.label')\n",
    "test_data = read_data(path, 'test.data')\n",
    "\n",
    "err = naive_bayes(m, pi, test_data, test_label)\n",
    "print \"Error Rate: \", err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nlen_test_data = test_data.shape[0]\\nnumber_doc_plus_1 = len(test_label)\\ntest_m = np.zeros((number_doc_plus_1, 61189))\\nfor i in range(len_test_data):\\n    data_iter = iter(test_data[i])\\n    doc_id = next(data_iter)\\n    word_id = next(data_iter)\\n    count = next(data_iter)\\n    test_m[doc_id][word_id] += count\\n\\n# log(1+f)\\ntest_m = np.log2(1+test_m)\\nerror = 0\\nfor i in range(1, number_doc_plus_1):\\n    cur_doc = test_m[i]\\n    cur_s = np.sum(cur_doc * m, axis = 1)\\n    final = cur_s + pi\\n    final = final[1:]\\n    label = np.argmax(final) + 1\\n    if label != test_label[i]:\\n        error += 1\\nreturn error * 100.0 / (number_doc_plus_1 - 1)\\n\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "len_test_data = test_data.shape[0]\n",
    "number_doc_plus_1 = len(test_label)\n",
    "test_m = np.zeros((number_doc_plus_1, 61189))\n",
    "for i in range(len_test_data):\n",
    "    data_iter = iter(test_data[i])\n",
    "    doc_id = next(data_iter)\n",
    "    word_id = next(data_iter)\n",
    "    count = next(data_iter)\n",
    "    test_m[doc_id][word_id] += count\n",
    "\n",
    "# log(1+f)\n",
    "test_m = np.log2(1+test_m)\n",
    "error = 0\n",
    "for i in range(1, number_doc_plus_1):\n",
    "    cur_doc = test_m[i]\n",
    "    cur_s = np.sum(cur_doc * m, axis = 1)\n",
    "    final = cur_s + pi\n",
    "    final = final[1:]\n",
    "    label = np.argmax(final) + 1\n",
    "    if label != test_label[i]:\n",
    "        error += 1\n",
    "return error * 100.0 / (number_doc_plus_1 - 1)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
